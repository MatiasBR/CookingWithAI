{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOHn9wh8WrOXBryqVye3ewU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpEWT2R6l_ON","executionInfo":{"status":"ok","timestamp":1727295054486,"user_tz":180,"elapsed":23671,"user":{"displayName":"Juan Cruz Gonzalez","userId":"11020053803992779413"}},"outputId":"b1002969-f872-4241-8f39-cb642745eb06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","# Ruta de la carpeta de imágenes y del CSV en Google Drive\n","image_dir = '/content/drive/My Drive/Proyecto-DataSets/imagenes_claras'\n","csv_file = '/content/drive/My Drive/Proyecto-DataSets/dataset.csv'\n","\n","# Cargar el CSV\n","df = pd.read_csv(csv_file)\n","df['image'] = df['image'].astype(str).fillna('')\n","\n","# Listas para almacenar imágenes válidas y filas válidas\n","valid_images = []\n","valid_rows = []\n","\n","# Verificar la existencia de cada imagen en el CSV\n","for i, row in df.iterrows():\n","    image_path = os.path.join(image_dir, row['image'])\n","    if os.path.exists(image_path):\n","        valid_images.append(row['image'])\n","        valid_rows.append(row)\n","\n","# Crear un nuevo DataFrame con solo las filas válidas\n","df_clean = pd.DataFrame(valid_rows)\n","\n","# Guardar el nuevo CSV limpio en Google Drive\n","clean_csv_path = '/content/drive/My Drive/Proyecto-DataSets/dataset_clean.csv'\n","df_clean.to_csv(clean_csv_path, index=False)\n","\n","print(f\"Total de imágenes válidas: {len(valid_images)}\")\n","print(f\"Nuevo CSV generado en: {clean_csv_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4jRJYmRNnSE2","executionInfo":{"status":"ok","timestamp":1727295068294,"user_tz":180,"elapsed":13812,"user":{"displayName":"Juan Cruz Gonzalez","userId":"11020053803992779413"}},"outputId":"ff7bea51-8173-4fe6-8bd2-7d024943a1c8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Total de imágenes válidas: 2596\n","Nuevo CSV generado en: /content/drive/My Drive/Proyecto-DataSets/dataset_clean.csv\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import pandas as pd # pandas es para manejar el .csv labels y eso, de manera eficiente.\n","import os\n","import numpy as np\n","from sklearn.utils import class_weight\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","dataset_path = '/content/drive/My Drive/Proyecto-DataSets/imagenes_claras'\n","csv_file = '/content/drive/My Drive/Proyecto-DataSets/dataset_clean.csv'\n","df = pd.read_csv(csv_file)\n","\n","datagen = ImageDataGenerator(\n","    rescale=1./255, # normalizacion los valores de píxel entre 0 y 1\n","    validation_split=0.2 # % 80 training, 20 % test\n",")\n","\n","df['image'] = df['image'].astype(str)\n","df['label'] = df['label'].astype(str)\n","\n","# training\n","train_generator = datagen.flow_from_dataframe(\n","    dataframe=df,\n","    directory=dataset_path,\n","    x_col=\"image\",\n","    y_col=\"label\",\n","    target_size=(224, 224),  # estandar\n","    class_mode=\"categorical\",  # clasificación multiclase\n","    batch_size=32,  # tamaño de batch\n","    subset=\"training\",  # usar esta parte para el entrenamiento\n","    shuffle=True,\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","# validacion/test\n","validation_generator = datagen.flow_from_dataframe(\n","    dataframe=df,\n","    directory=dataset_path,\n","    x_col=\"image\",\n","    y_col=\"label\",\n","    target_size=(224, 224), # estandar\n","    class_mode=\"categorical\", # clasificación multiclase\n","    batch_size=32,  # tamaño de batch\n","    subset=\"validation\",  # Usar esta parte para validación\n","    fill_mode='nearest'\n",")\n","\n","\n","# Calcular pesos de clase para el balanceo. (20 fotos de un ingrediente y 4 del otro)\n","class_labels = df['label'].astype(str).values\n","class_weights = class_weight.compute_class_weight(\n","    'balanced',\n","    classes=np.unique(class_labels),\n","    y=class_labels\n",")\n","class_weight_dict = dict(enumerate(class_weights))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rzvLAJdsn6_R","executionInfo":{"status":"ok","timestamp":1727295077201,"user_tz":180,"elapsed":8911,"user":{"displayName":"Juan Cruz Gonzalez","userId":"11020053803992779413"}},"outputId":"ceeb19ff-395b-41a6-f4e5-f24aeadc8e19"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2077 validated image filenames belonging to 109 classes.\n","Found 519 validated image filenames belonging to 109 classes.\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.applications import MobileNetV2\n","import tensorflow as tf\n","\n","base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# esto es para prevenir el sobreajuste yo congelo todas las capas de mobilenet y solo extraigo lo que me sirve de mobile net\n","# que es el reconocimiento de imagenes, no ir cambiando los pesos durante el entrenamiento.\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","model = Sequential([\n","    base_model, # aca estaria todo lo que es filtrado y agrupamiento (Conv2d y MaxPooling2d)\n","    # luego del modelo base, hago yo nuevas capas de entrenamiento para mi problema particular.\n","    # procesamiento de las imagenes y clasificacion.\n","    Flatten(),\n","    Dense(256, activation='relu'),\n","    Dropout(0.5),\n","    Dense(len(np.unique(df['label'])), activation='softmax') # agarra los labels unicos es decir una neurona por cada clase\n","])\n","\n","# compilacion\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# un resumen si se quiere\n","# model.summary()\n","\n","# Early stopping si fuera necesario\n","early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n","\n","# ir agarrando el mejor modelo a medida que pase el entrenamiento\n","checkpoint = ModelCheckpoint(\n","    '/content/drive/My Drive/Proyecto-DataSets/mejorModelo.keras',\n","    monitor='val_loss',\n","    save_best_only=True\n",")\n","\n"],"metadata":{"id":"f1-8HtQHpWzf","executionInfo":{"status":"ok","timestamp":1727296756230,"user_tz":180,"elapsed":825,"user":{"displayName":"Juan Cruz Gonzalez","userId":"11020053803992779413"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // validation_generator.batch_size,\n","    epochs=20,\n","    class_weight=class_weight_dict,\n","    callbacks=[early_stopping, checkpoint]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OiOwqy4Ur3fw","executionInfo":{"status":"ok","timestamp":1727296990364,"user_tz":180,"elapsed":228816,"user":{"displayName":"Juan Cruz Gonzalez","userId":"11020053803992779413"}},"outputId":"04ac8a1b-9c2f-4d34-e734-a120aacd19ed"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 826ms/step - accuracy: 0.1639 - loss: 5.5226 - val_accuracy: 0.0488 - val_loss: 5.2844\n","Epoch 2/20\n","\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4375 - loss: 8.0492 - val_accuracy: 0.0000e+00 - val_loss: 6.2749\n","Epoch 3/20\n","\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 664ms/step - accuracy: 0.5512 - loss: 2.7994 - val_accuracy: 0.0430 - val_loss: 6.2225\n","Epoch 4/20\n","\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4062 - loss: 1.9683 - val_accuracy: 0.0000e+00 - val_loss: 6.3741\n","Epoch 5/20\n","\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 663ms/step - accuracy: 0.6696 - loss: 1.9572 - val_accuracy: 0.0430 - val_loss: 7.7455\n","Epoch 6/20\n","\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.6250 - loss: 1.2909 - val_accuracy: 0.0000e+00 - val_loss: 8.6344\n","Epoch 7/20\n","\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 673ms/step - accuracy: 0.7811 - loss: 1.3260 - val_accuracy: 0.0410 - val_loss: 8.2441\n","Epoch 8/20\n","\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.7175 - val_accuracy: 0.1429 - val_loss: 6.8996\n"]}]},{"cell_type":"code","source":["val_loss, val_accuracy = model.evaluate(validation_generator)\n","print(f\"Pérdida en validación: {val_loss}\")\n","print(f\"Precisión en validación: {val_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9QVBXE5r9Rp","executionInfo":{"status":"ok","timestamp":1727297061535,"user_tz":180,"elapsed":12130,"user":{"displayName":"Juan Cruz Gonzalez","userId":"11020053803992779413"}},"outputId":"8b917702-60a5-47b9-b4ba-ef8d29bc302b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 574ms/step - accuracy: 0.0433 - loss: 5.3131\n","Pérdida en validación: 5.298048496246338\n","Precisión en validación: 0.04816955700516701\n"]}]},{"cell_type":"code","source":["model_save_path = '/content/drive/My Drive/Proyecto-DataSets/modeloEntrenado.keras'\n","model.save(model_save_path)"],"metadata":{"id":"a4VUCPLer9tC","executionInfo":{"status":"ok","timestamp":1727297078677,"user_tz":180,"elapsed":12985,"user":{"displayName":"Juan Cruz Gonzalez","userId":"11020053803992779413"}}},"execution_count":11,"outputs":[]}]}